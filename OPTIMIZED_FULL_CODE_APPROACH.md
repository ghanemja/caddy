# Optimized Full Code Generation Approach

## Decision: Full Code > Search-Replace

Reverted back to having VLM output the complete Python file, but with **major optimizations** based on lessons learned.

## Why Full Code Is Better

**Your reasoning:**
- VLM can see the full context
- Can make intelligent multi-parameter changes
- More natural for code generation models
- The 620-line output showed it CAN work

**The 620-line output was actually good!** Just needed:
- ‚úÖ Better stopping (prevent truncation)
- ‚úÖ Lower temperature (prevent hallucination)
- ‚úÖ More tokens (allow full output)
- ‚úÖ Clearer instructions (selective modification)

## Optimizations Applied

### 1. **Selective Modification Emphasis**

**New prompt focus:**
```
‚ö†Ô∏è If user asks for specific change (e.g., "set wheels to 4"), make ONLY that change
‚ö†Ô∏è If user says "match the image", identify what differs and change those parameters
‚ö†Ô∏è DO NOT change parameters that weren't requested and don't need changing
```

**Example given:**
- User says: "set wheels to 4"
- You change: ONLY `wheels_per_side` line
- You copy: Everything else unchanged

### 2. **Increased Max Tokens** (Line 1629)

**Before:** 4096 tokens
**After:** 6144 tokens

**Why:** Can output ~230 lines comfortably (was getting truncated at 200)

### 3. **Lower Temperature** (Line 1630)

**Before:** 0.05
**After:** 0.01

**Why:** More deterministic = less hallucination, better copying

### 4. **Higher Repetition Penalty** (Line 1639)

**Before:** 1.05
**After:** 1.1

**Why:** Prevents getting stuck repeating methods (like the duplicate mate_ methods we saw)

### 5. **Clear "No Markdown" Rule**

**Emphasized:**
```
‚ö†Ô∏è Output ONLY valid Python code - NO explanations, NO markdown fences (```), NO extra text
‚ö†Ô∏è Start immediately with #!/usr/bin/env python3
```

### 6. **Simplified Validation**

**Removed:** Complex 8-point validation (overkill now)
**Kept:** 
- Syntax validation (`compile()`)
- Basic extraction check
- File saving with backups

**Why:** If we start with valid baseline and make minimal changes, result should be valid

## Generation Parameters Summary

```python
max_new_tokens = 6144   # ~230 lines of code
temperature = 0.01      # Very deterministic
top_p = 0.98           # High (allows some variety)
repetition_penalty = 1.1  # Prevent loops
```

## Expected Behavior Now

### User Prompt: "set wheels_per_side to 4"

**VLM will:**
1. Read baseline (180 lines)
2. Find: `wheels_per_side = PositiveFloat(6)  # default 6 per side`
3. Change to: `wheels_per_side = PositiveFloat(4)  # default 4 per side`
4. Copy everything else exactly
5. Output 180 lines of complete, valid code

**Console Output:**
```
[vlm] Generated with max_tokens=6144, temp=0.01
[vlm] ‚úì Got response: ~5800 chars
[codegen] ‚úì Extracted 5721 chars of Python code
[codegen] ‚úì Generated code compiles successfully
[codegen] ‚úì Saved to generated/robot_base_vlm.py
[codegen] Code: 5721 chars, 181 lines
[reload] ‚úì Loaded Rover from generated code
[rebuild] ‚úì Saved GLB to assets/rover.glb
```

**Result:** 8 wheels appear (4 per side)!

## Key Improvements Over Previous Attempts

| Issue | Before | After |
|-------|--------|-------|
| **Truncation** | Cut off at 619 lines | 6144 tokens = full output |
| **Hallucination** | Duplicate methods | Repetition penalty 1.1 |
| **Over-modification** | Changed everything | "Change ONLY what requested" |
| **Markdown** | Added ```python | "NO markdown fences" |
| **Abbreviation** | Used ... | "DO NOT use ..." |
| **Temperature** | 0.1 (too random) | 0.01 (very precise) |

## Testing

```bash
conda activate cad-optimizer
cd cqparts_bucket
python optim.py
```

### Test 1: Specific Modification
1. Upload any reference image
2. Prompt: **"set wheels_per_side to 3"**
3. Click "Generate Code"
4. **Expected:** 
   - Output: 180+ lines
   - Changed: Only wheels_per_side line
   - Wheels appear: 6 total (3 per side)

### Test 2: Image-Based
1. Upload image with different wheel count
2. Prompt: **"match the reference image for wheel count"**
3. Click "Generate Code"
4. **Expected:**
   - VLM analyzes image
   - Changes wheels_per_side to match
   - Copies everything else

### Test 3: Multiple Changes
1. Upload image with bigger chassis + more wheels
2. Prompt: **"match the image - adjust both size and wheels"**
3. **Expected:**
   - Changes length, width, wheels_per_side
   - Copies all methods unchanged
   - 180+ lines of valid code

## What We Learned

The 620-line output proved the VLM **can** copy code! Problems were:

1. **Truncation** - Needed more tokens ‚úÖ FIXED (6144)
2. **Duplication** - Needed repetition penalty ‚úÖ FIXED (1.1)
3. **Markdown fences** - extract_python_module() handles this ‚úÖ WORKS
4. **Over-eager changes** - Now emphasizes selective modification ‚úÖ IMPROVED

## Files Modified

1. **`optim.py`** (Lines 1041-1061):
   - Reverted to full code output prompt
   - Emphasized selective modification
   - Added user instruction awareness

2. **`optim.py`** (Lines 1214-1253):
   - Updated final instructions
   - Clearer about when to change parameters
   - Strong "no markdown" warning

3. **`optim.py`** (Lines 1311-1397):
   - Reverted backend to extract Python
   - Removed search-replace logic
   - Simpler validation

4. **`optim.py`** (Lines 1629-1642):
   - Increased max_tokens: 6144
   - Decreased temperature: 0.01
   - Increased repetition_penalty: 1.1

5. **`app.js`** (Lines 865-872):
   - Simplified display logic
   - Removed search-replace specific UI

## Next Steps

**Try generating now!** The VLM should:
- Output ~180 lines (not 48, not 600+)
- Include ALL imports and methods
- Change ONLY requested parameters
- No markdown fences
- No truncation
- **Wheels will appear!**

The system is now optimized for the full-code approach! üöÄ

